
<!doctype html>
<!-- The DOCTYPE declaration above will set the     -->
<!-- browser's rendering engine into                -->
<!-- "Standards Mode". Replacing this declaration   -->
<!-- with a "Quirks Mode" doctype is not supported. -->

<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<!--                                                               -->
<!-- Consider inlining css to reduce the number of requested files -->
<!--                                                               -->
<link rel="shortcut icon" type="image/x-icon" href="../images/favicon.ico" />
<link type="text/css" rel="stylesheet" href="../css/bootstrap.min.css">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link type="text/css" rel="stylesheet" href="../css/rajkumar.css"

<!--                                           -->
<!-- Any title is fine                         -->
<!--                                           -->
<title>Rajkumar Pujari</title>

<!--                                           -->
<!-- This script loads your compiled module.   -->
<!-- If you add any GWT meta tags, they must   -->
<!-- be added before this line.                -->
<!--                                           -->
<script type="text/javascript" language="javascript"
	src="https://rajkumar-pujari.com/pubpages/js/bootstrap.min.js"></script>
	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79894772-1', 'auto');
  ga('send', 'pageview');

</script>
</head>


<body>
	<div class="container">
		<center>
			<h2>Rajkumar Pujari</h2>
		</center>

		<hr class="nomargin">
		<nav class=mynavbar>
			<a href="../index.html">HOME</a>
				<a href="../publications.html"><span class="focus">PUBLICATIONS</span></a>
				<a href="../software.html">SOFTWARE</a>
				<a href="../contact.html">CONTACT</a>
				<a href="../cv.html">CV</a>
			
		
		</nav>
		<hr class="nomargin">
		<br>

		

		<center>
		<iframe width="840" height="472" src="https://www.youtube.com/embed/HacUn-ZOyYc?rel=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
		
		<div class="publication">
            <h4 style="margin-bottom:0px; font-weight:bold; text-align:center;">
                "We Demand Justice!": Towards Social Context Grounding of Political Texts 
                <span>(<a href="https://arxiv.org/abs/2311.09106">link</a>, <a href="https://rajkumar-pujari.com/pubpages/data/language_in_context_ppt.pdf">presentation</a>, <a href="https://rajkumar-pujari.com/pubpages/data/language_in_context_poster.pdf">poster</a>)</span>
            </h4>
            <span style="color:#991818">Rajkumar Pujari, Chengfei Wu, and Dan Goldwasser</span><br>
            <span style="color:#991818">Long paper at EMNLP 2024</span><br>
        </div>

        <div class="content row">
            <p style="text-align:left">
                <strong>Abstract:</strong>
                Political discourse on social media often contains similar language with opposing intended meanings. For example, the phrase thoughts and prayers, is used to express sympathy for mass shooting victims, as well as satirically criticize the lack of legislative action on gun control. Understanding such discourse fully by reading only the text is difficult. However, knowledge of the social context information makes it easier.
            </p>
        
            <p style="text-align:left;">
                We characterize the social context required to fully understand such ambiguous discourse, by grounding the text in real-world entities, actions, and attitudes. We propose two datasets that require an understanding of social context and benchmark them using large pre-trained language models and several novel structured models. We show that structured models, explicitly modeling social context, outperform larger models on both tasks, but still lag significantly behind human performance. Finally, we perform an extensive analysis, to obtain further insights into the language understanding challenges posed by our social grounding tasks.
            </p>
        </div>


		</center>

	</div>

</body>
</html>

